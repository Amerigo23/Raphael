{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Related third party imports\n",
    "import janitor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dense, LSTM, LeakyReLU\n",
    "# from keras.optimizers import Adam\n",
    "import pydoc_data\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Local application/library specific imports\n",
    "# (None in this example, but this is where they would go)\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "google_credentials = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amermujkanovic/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to DataFrame is deprecated and will raise in a future version. Use public APIs instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "PROJECT = \"focus-hulling-416322\"\n",
    "DATASET = \"2016\"\n",
    "TABLE = \"out_and_in_2016_v4\"\n",
    "\n",
    "# Ensure the project, dataset, and table names are correctly formatted\n",
    "# using backticks to avoid syntax errors\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{PROJECT}.{DATASET}.{TABLE}`\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT)\n",
    "query_job = client.query(query)\n",
    "result = query_job.result()\n",
    "data = result.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID    Gender  age_years  region_mod  Relationship_To_Primary_Beneficiary  Patient_Zipcode  Health_Plan_Type  plan_typ  Clinic  drg  Clinic_visits  Myocardial_infarction  chf  pvd  Cardiovascular_d  Respiratory_d  Hypertension  Diabetes_Melitus  Dementia  Kidney_disease  Liver_disease  Diarrheal_disease  Cancer  Metastasis  Connective_tissue_disease  puc  hemiplegia  lymphoma  aids  lohs  Coinsurance  Copay  Deductable   Net           Pay           trauma\n",
       "2.030200e+04  2       61.0       2           2                                    0.0              0                 6.0       2       0    16             0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     126.919963   0.0    699.999619   593.379808    1451.939667   0         1\n",
       "4.011262e+09  1       59.0       4           2                                    41740.0          0                 9.0       2       0    16             0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     1065.219434  0.0    560.849854   14316.192814  15942.273003  0         1\n",
       "4.011258e+09  1       19.0       4           3                                    41740.0          0                 9.0       2       0    9              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     0.000000     0.0    807.839966   1010.269787   1818.109753   0         1\n",
       "                      59.0       4           1                                    11244.0          0                 9.0       2       0    12             0.0                    0.0  1.0  0.0               0.0            2.0           0.0               0.0       0.0             0.0            0.0                1.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     258.279917   0.0    1799.469393  2324.609253   4382.357668   0         1\n",
       "4.011259e+09  1       9.0        4           3                                    41740.0          0                 9.0       2       0    3              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     0.000000     0.0    125.699951   247.929871    373.629822    0         1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
       "2.546756e+09  2       59.0       2           2                                    49660.0          0                 4.0       2       0    4              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     32.250000    40.0   3.599998     219.019897    449.239922    0         1\n",
       "                                                                                                                     6.0       2       0    4              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     84.279972    20.0   0.000000     362.119896    596.039703    0         1\n",
       "2.546757e+09  2       54.0       2           1                                    18140.0          0                 6.0       2       0    24             0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                2.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     1085.489807  0.0    199.999928   4862.768887   6148.257996   0         1\n",
       "                      13.0       2           3                                    18140.0          0                 4.0       2       0    8              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     859.359802   115.0  0.000000     3699.378830   4673.738815   0         1\n",
       "3.404382e+10  1       41.0       3           1                                    36420.0          1                 5.0       2       0    1              0.0                    0.0  0.0  0.0               0.0            0.0           0.0               0.0       0.0             0.0            0.0                0.0     0.0         0.0                        0.0  0.0         0.0       0.0   0     0.000000     0.0    121.749939   0.000000      121.749939    0         1\n",
       "Name: count, Length: 2763169, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clinic\n",
       "2    2476959\n",
       "1     340194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clinic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinic_inpatient\n",
      "0.0    1789957\n",
      "1.0     242863\n",
      "Name: count, dtype: int64\n",
      "clinic_outpatient\n",
      "1.0    2032555\n",
      "0.0        265\n",
      "Name: count, dtype: int64\n",
      "both_clinic\n",
      "0    1845385\n",
      "1     187435\n",
      "Name: count, dtype: int64\n",
      "gender_female\n",
      "0.0    1262051\n",
      "1.0     770769\n",
      "Name: count, dtype: int64\n",
      "gender_male\n",
      "1.0    1262051\n",
      "0.0     770769\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['clinic_inpatient'].value_counts())\n",
    "print(df['clinic_outpatient'].value_counts())\n",
    "print(df['both_clinic'].value_counts())\n",
    "print(df['gender_female'].value_counts())\n",
    "print(df['gender_male'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amermujkanovic/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the column names\n",
    "df = data.clean_names()\n",
    "\n",
    "# Changin the values inside the clinic column for onehot encoding\n",
    "value_map = {1: 'Inpatient', 2: 'Outpatient'}\n",
    "df['clinic'] = df['clinic'].map(value_map)\n",
    "\n",
    "#Chaning the values for region_mod\n",
    "value_map_2 = {'1': 'northeast', '2':'northcentral', '3':'south', '4':'west', '5':'unknown'}\n",
    "df['region_mod'] = df['region_mod'].map(value_map_2)\n",
    "\n",
    "#chaning the gender varible\n",
    "value_map_3 = {'1':'male', '2':'female'}\n",
    "df['gender'] = df['gender'].map(value_map_3)\n",
    "\n",
    "# # Creating values for Plantype\n",
    "# value_map_4 = {1: 'basic', 2: 'comprihensive', 3:'epo', 4:'hmo', 5:'pos', 6:'ppo', 7:'pos2', 8:'cdhp', 9:'hdhp'}\n",
    "\n",
    "\n",
    "def encode_and_bind(original_dataframe, features_to_encode):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    # Convert a single feature name to a list\n",
    "    if isinstance(features_to_encode, str):\n",
    "        features_to_encode = [features_to_encode]\n",
    "\n",
    "    # Check if the features exist in the dataframe\n",
    "    for feature in features_to_encode:\n",
    "        if feature not in original_dataframe.columns:\n",
    "            raise ValueError(f\"Feature '{feature}' not found in the dataframe\")\n",
    "\n",
    "    # One-hot encoding\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(original_dataframe[features_to_encode])\n",
    "    encoded_features = encoder.transform(original_dataframe[features_to_encode])\n",
    "\n",
    "    # Add new encoded columns to the dataframe\n",
    "    original_dataframe[encoder.get_feature_names_out(features_to_encode)] = encoded_features\n",
    "\n",
    "    # Drop the original columns\n",
    "    original_dataframe.drop(columns=features_to_encode, inplace=True)\n",
    "\n",
    "    # Return the modified dataframe\n",
    "    return original_dataframe\n",
    "\n",
    "features_to_encode = ['clinic', 'region_mod', 'gender']\n",
    "\n",
    "encode_and_bind(df, features_to_encode)\n",
    "\n",
    "value_to_encode = [183, 184, 185, 521, 522, 533, 534, 545, 536, 542, 543, 544, 562, 563]\n",
    "df['trauma'] = df['drg'].apply(lambda x: 1 if x in value_to_encode else 0)\n",
    "\n",
    "\n",
    "\n",
    "#cleaning names again\n",
    "df = df.clean_names()\n",
    "\n",
    "group_columns = ['patient_id', 'gender_male', 'relationship_to_primary_beneficiary']\n",
    "\n",
    "agg_dict = {col: 'sum' for col in df.columns if col not in group_columns}\n",
    "agg_dict['age_years'] = 'mean'\n",
    "df = df.groupby(group_columns).agg(agg_dict).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "#replacing the values greater than 1\n",
    "\n",
    "\n",
    "# #sorting out patient_id column\n",
    "df['patient_id'] = df['patient_id'].astype(str)\n",
    "df['patient_id'] = df['patient_id'].str.slice(0, -2)\n",
    "\n",
    "# #eliminating the negative pay values\n",
    "\n",
    "df = df[(df['age_years'] > 17) & (df['pay'].between(2,1000000))]\n",
    "\n",
    "\n",
    "\n",
    "#removing the duplicates\n",
    "duplicates = df.duplicated(subset='patient_id', keep=False)\n",
    "duplicate_rows= df[duplicates]\n",
    "duplicate_rows.sort_values(by='patient_id')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['both_clinic'] = np.where((df['clinic_inpatient'] == 1.0) & (df['clinic_outpatient'] == 1.0), 1,0)\n",
    "\n",
    "# CCI score\n",
    "df['cci'] = 0\n",
    "df['cci']= pd.cut(df['age_years'],\n",
    "                    bins=[0, 49, 59, 69, 79, float('inf')],\n",
    "                    labels=[0, 1, 2, 3, 4],\n",
    "                    right=False).astype(int)\n",
    "df.loc[df['myocardial_infarction'] == 1, 'cci'] +=1\n",
    "df.loc[df['chf'] == 1, 'cci'] +=1\n",
    "df.loc[df['pvd'] == 1, 'cci'] +=1\n",
    "df.loc[df['respiratory_d'] == 1, 'cci'] +=1\n",
    "df.loc[df['connective_tissue_disease'] == 1, 'cci'] +=1\n",
    "df.loc[df['liver_disease'] == 1, 'cci'] +=1\n",
    "df.loc[df['diabetes_melitus'] == 1, 'cci'] +=1\n",
    "df.loc[df['kidney_disease'] == 1, 'cci'] +=1\n",
    "df.loc[df['puc'] == 1, 'cci'] +=1\n",
    "df.loc[df['hemiplegia'] == 1, 'cci'] +=2\n",
    "df.loc[df['lymphoma'] == 1, 'cci'] +=2\n",
    "df.loc[df['aids'] == 1, 'cci'] +=6\n",
    "df.loc[df['cancer'] == 1, 'cci'] +=2\n",
    "df.loc[df['metastasis'] == 1, 'cci'] +=6\n",
    "\n",
    "scaling_columns = ['lohs', 'clinic_visits', 'age_years']\n",
    "def scaler_minmax(data_frame, scaling_columns):\n",
    "    minmax = MinMaxScaler()\n",
    "    if isinstance(scaling_columns, str):  # If a single column name is passed as a string\n",
    "        scaling_columns = [scaling_columns]  # Convert it to a list\n",
    "\n",
    "    minmax.fit(data_frame[scaling_columns])\n",
    "    data_frame[scaling_columns] = minmax.transform(data_frame[scaling_columns])\n",
    "\n",
    "scaler_minmax(df, scaling_columns)\n",
    "\n",
    "columns_to_replace = [\n",
    "    'myocardial_infarction', 'trauma', 'chf', 'pvd', 'cardiovascular_d',\n",
    "    'respiratory_d', 'hypertension', 'diabetes_melitus', 'dementia',\n",
    "    'kidney_disease', 'liver_disease', 'diarrheal_disease', 'cancer',\n",
    "    'metastasis', 'puc', 'hemiplegia', 'lymphoma', 'aids',\n",
    "    'connective_tissue_disease', 'region_mod_northcentral',\n",
    "    'region_mod_northeast', 'region_mod_south', 'region_mod_west',\n",
    "    'region_mod_unknown', 'clinic_outpatient', 'clinic_inpatient', 'both_clinic', 'gender_female', 'gender_male'\n",
    "]\n",
    "\n",
    "new_value = 1\n",
    "\n",
    "for column in columns_to_replace:\n",
    "    df[column] = df[column].apply(lambda x: new_value if 2.0 <= x <= 200.0 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinic_inpatient\n",
      "0.0    1789957\n",
      "1.0     242863\n",
      "Name: count, dtype: int64\n",
      "clinic_outpatient\n",
      "1.0    2032555\n",
      "0.0        265\n",
      "Name: count, dtype: int64\n",
      "both_clinic\n",
      "0    1845385\n",
      "1     187435\n",
      "Name: count, dtype: int64\n",
      "gender_female\n",
      "0.0    1262051\n",
      "1.0     770769\n",
      "Name: count, dtype: int64\n",
      "gender_male\n",
      "1.0    1262051\n",
      "0.0     770769\n",
      "Name: count, dtype: int64\n",
      "region_mod_unknown\n",
      "0.0    2024214\n",
      "1.0       8606\n",
      "Name: count, dtype: int64\n",
      "0.6674917267219399\n",
      "diabetes_melitus\n",
      "0.0    1715965\n",
      "1.0     316855\n",
      "Name: count, dtype: int64\n",
      "0.0019333601453801641\n"
     ]
    }
   ],
   "source": [
    "print(df['clinic_inpatient'].value_counts())\n",
    "print(df['clinic_outpatient'].value_counts())\n",
    "print(df['both_clinic'].value_counts())\n",
    "print(df['gender_female'].value_counts())\n",
    "print(df['gender_male'].value_counts())\n",
    "print(df['region_mod_unknown'].value_counts())\n",
    "print(df['age_years'].mean())\n",
    "print(df['diabetes_melitus'].value_counts())\n",
    "print(df['lohs'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'gender_male', 'relationship_to_primary_beneficiary',\n",
       "       'age_years', 'patient_zipcode', 'health_plan_type', 'plan_typ', 'drg',\n",
       "       'clinic_visits', 'myocardial_infarction', 'chf', 'pvd',\n",
       "       'cardiovascular_d', 'respiratory_d', 'hypertension', 'diabetes_melitus',\n",
       "       'dementia', 'kidney_disease', 'liver_disease', 'diarrheal_disease',\n",
       "       'cancer', 'metastasis', 'connective_tissue_disease', 'puc',\n",
       "       'hemiplegia', 'lymphoma', 'aids', 'lohs', 'coinsurance', 'copay',\n",
       "       'deductable', 'net', 'pay', 'trauma', 'clinic_inpatient',\n",
       "       'clinic_outpatient', 'region_mod_northcentral', 'region_mod_northeast',\n",
       "       'region_mod_south', 'region_mod_unknown', 'region_mod_west',\n",
       "       'gender_female', 'both_clinic', 'cci'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.032820e+06\n",
       "mean     1.201522e+00\n",
       "std      1.207555e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      2.000000e+00\n",
       "max      1.500000e+01\n",
       "Name: cci, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.hist(df['cci'], bins=30, edgecolor='black')\n",
    "df['cci'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outliers ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the X and the y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\n",
    "X = df.drop(columns=['pay', 'clinic_outpatient', 'patient_zipcode', 'patient_id', 'health_plan_type', 'plan_typ', 'drg', 'relationship_to_primary_beneficiary', 'coinsurance', 'copay', 'deductable', 'net', 'region_mod_unknown'])\n",
    "\n",
    "y = df['pay']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_male</th>\n",
       "      <th>age_years</th>\n",
       "      <th>clinic_visits</th>\n",
       "      <th>myocardial_infarction</th>\n",
       "      <th>chf</th>\n",
       "      <th>pvd</th>\n",
       "      <th>cardiovascular_d</th>\n",
       "      <th>respiratory_d</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes_melitus</th>\n",
       "      <th>...</th>\n",
       "      <th>trauma</th>\n",
       "      <th>clinic_inpatient</th>\n",
       "      <th>clinic_outpatient</th>\n",
       "      <th>region_mod_northcentral</th>\n",
       "      <th>region_mod_northeast</th>\n",
       "      <th>region_mod_south</th>\n",
       "      <th>region_mod_west</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>both_clinic</th>\n",
       "      <th>cci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.059943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.050428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298457</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298458</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298459</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298460</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2032820 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender_male  age_years  clinic_visits  myocardial_infarction  chf  \\\n",
       "0                0.0   0.914894       0.014272                    0.0  0.0   \n",
       "1                1.0   0.978723       0.001903                    0.0  0.0   \n",
       "2                0.0   0.744681       0.074215                    0.0  0.0   \n",
       "3                1.0   0.914894       0.059943                    0.0  0.0   \n",
       "4                1.0   0.893617       0.050428                    0.0  0.0   \n",
       "...              ...        ...            ...                    ...  ...   \n",
       "2298456          0.0   0.872340       0.006660                    0.0  0.0   \n",
       "2298457          1.0   0.297872       0.006660                    0.0  0.0   \n",
       "2298458          1.0   0.723404       0.028544                    0.0  0.0   \n",
       "2298459          1.0   0.382979       0.003806                    0.0  0.0   \n",
       "2298460          1.0   0.489362       0.000000                    0.0  0.0   \n",
       "\n",
       "         pvd  cardiovascular_d  respiratory_d  hypertension  diabetes_melitus  \\\n",
       "0        0.0               0.0            0.0           0.0               0.0   \n",
       "1        0.0               0.0            0.0           0.0               0.0   \n",
       "2        0.0               0.0            0.0           1.0               0.0   \n",
       "3        0.0               0.0            0.0           1.0               1.0   \n",
       "4        0.0               0.0            1.0           1.0               0.0   \n",
       "...      ...               ...            ...           ...               ...   \n",
       "2298456  0.0               0.0            0.0           0.0               1.0   \n",
       "2298457  0.0               0.0            0.0           0.0               0.0   \n",
       "2298458  0.0               0.0            0.0           0.0               0.0   \n",
       "2298459  0.0               0.0            0.0           0.0               0.0   \n",
       "2298460  0.0               0.0            0.0           0.0               0.0   \n",
       "\n",
       "         ...  trauma  clinic_inpatient  clinic_outpatient  \\\n",
       "0        ...       0               0.0                1.0   \n",
       "1        ...       0               0.0                1.0   \n",
       "2        ...       0               1.0                1.0   \n",
       "3        ...       1               1.0                1.0   \n",
       "4        ...       0               0.0                1.0   \n",
       "...      ...     ...               ...                ...   \n",
       "2298456  ...       0               0.0                1.0   \n",
       "2298457  ...       0               0.0                1.0   \n",
       "2298458  ...       0               0.0                1.0   \n",
       "2298459  ...       0               0.0                1.0   \n",
       "2298460  ...       0               0.0                1.0   \n",
       "\n",
       "         region_mod_northcentral  region_mod_northeast  region_mod_south  \\\n",
       "0                            1.0                   0.0               0.0   \n",
       "1                            1.0                   0.0               0.0   \n",
       "2                            1.0                   0.0               0.0   \n",
       "3                            1.0                   0.0               0.0   \n",
       "4                            1.0                   0.0               0.0   \n",
       "...                          ...                   ...               ...   \n",
       "2298456                      0.0                   0.0               1.0   \n",
       "2298457                      0.0                   0.0               1.0   \n",
       "2298458                      0.0                   0.0               1.0   \n",
       "2298459                      1.0                   0.0               0.0   \n",
       "2298460                      0.0                   0.0               1.0   \n",
       "\n",
       "         region_mod_west  gender_female  both_clinic  cci  \n",
       "0                    0.0            1.0            0    2  \n",
       "1                    0.0            0.0            0    2  \n",
       "2                    0.0            1.0            1    2  \n",
       "3                    0.0            0.0            1    2  \n",
       "4                    0.0            0.0            0    3  \n",
       "...                  ...            ...          ...  ...  \n",
       "2298456              0.0            1.0            0    3  \n",
       "2298457              0.0            0.0            0    0  \n",
       "2298458              0.0            0.0            0    1  \n",
       "2298459              0.0            0.0            0    0  \n",
       "2298460              0.0            0.0            0    0  \n",
       "\n",
       "[2032820 rows x 32 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6086124662781021\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cv_result = cross_validate(DecisionTreeRegressor(max_depth=8, min_samples_leaf=7, min_samples_split=30), X_train, y_train, cv=5, scoring='r2')\n",
    "test_score = cv_result['test_score'].mean()\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Random Forrest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest regressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Grid Search for Hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_validate(RandomForestRegressor(max_depth=8,\n",
    "                                                 min_samples_leaf=7,\n",
    "                                                 min_samples_split=30,\n",
    "                                                 n_estimators=200,\n",
    "                                                 criterion='squared_error',\n",
    "                                                 max_features='sqrt'),\n",
    "                           X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "test_score_rf = cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=8, min_samples_leaf=7, min_samples_split=300,\n",
       "                      n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=8, min_samples_leaf=7, min_samples_split=300,\n",
       "                      n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=8, min_samples_leaf=7, min_samples_split=300,\n",
       "                      n_estimators=200)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=200, min_samples_leaf=7, min_samples_split=30, max_depth=8)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 8596.17 dollars\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "errors = abs(y_pred_rf - y_test)\n",
    "print('Mean absolute error:', round(np.mean(errors),2), 'dollars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = cross_validate(GradientBoostingRegressor(n_estimators=200,\n",
    "                                               learning_rate=0.1,\n",
    "                                               min_samples_leaf=7,\n",
    "                                               max_depth=8,\n",
    "                                               min_samples_split=30,\n",
    "                                               random_state=42),\n",
    "                     X_train,\n",
    "                     y_train,\n",
    "                     cv=5,\n",
    "                     scoring='r2')\n",
    "\n",
    "test_score_gbm = gbm['test_score'].mean()\n",
    "test_score_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 662402098.5054079\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor(n_estimators=200,\n",
    "                                min_samples_split=30,\n",
    "                                min_samples_leaf=7,\n",
    "                                max_depth=8 ,\n",
    "                                learning_rate=0.1,\n",
    "                                random_state=42)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "#670160468.497997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/59\n",
      "35575/35575 [==============================] - 35s 988us/step - loss: 15598.3105 - mae: 15593.2246 - accuracy: 0.0000e+00 - val_loss: 15163.8262 - val_mae: 15163.7939 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/59\n",
      "35575/35575 [==============================] - 37s 1ms/step - loss: 92259.7422 - mae: 92256.9688 - accuracy: 0.0000e+00 - val_loss: 14915.6836 - val_mae: 14915.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/59\n",
      " 6427/35575 [====>.........................] - ETA: 22s - loss: 14807.4258 - mae: 14806.4443 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [143], line 44\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m),\n\u001b[1;32m     40\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     41\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test data\u001b[39;00m\n\u001b[1;32m     47\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:240\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    230\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    231\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    232\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_cache.py:50\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict[context]\u001b[38;5;241m.\u001b[39mdispatch(function_type)\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_primary\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:449\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 449\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:895\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "# Load dataset\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Normalizing the dataset\n",
    "# from sklearn.preprocessing import normalize\n",
    "# X_train_normalized = normalize(X_train, axis=0)\n",
    "# X_test_normalized = normalize(X_test, axis=0)\n",
    "\n",
    "# # Architecture one with relu and dropout rate\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, activation= 'relu', input_shape=(X.shape[1],),\n",
    "                       kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(layers.Dense(30, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l1(0.01)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l1(0.01)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "# eraly stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=15,\n",
    "                               verbose =1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "\n",
    "# # Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=[('mae', 'accuracy')])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=59, batch_size=32, validation_split=0.3, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "# print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7868.2763671875, 7836.2109375, 0.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "\n",
    "# 7788.56640625, 7788.56640625\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26110.428874302313"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(results[0])\n",
    "# 32131.827461257162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
